{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>While bismuth compounds Pepto Bismol decreased...</td>\n",
       "      <td>O,B-med,I-med,B-med,I-med,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Diarrhea  also spelled diarrhoea  is the condi...</td>\n",
       "      <td>B-diag,O,O,B-diag,O,O,O,I-diag,O,O,O,O,O,O,O,B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Antiretroviral therapy ART is recommended for ...</td>\n",
       "      <td>B-med,I-med,B-med,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The following drugs are considered as DMARDs  ...</td>\n",
       "      <td>O,O,O,O,O,O,B-med,B-med,B-med,B-med,B-med,B-me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The goals of treatment are to reduce pain  dec...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Bats are the most common source of rabies in h...</td>\n",
       "      <td>O,O,O,O,O,O,O,B-diag,O,O,O,O,O,O,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>In       following the outbreak of severe acut...</td>\n",
       "      <td>O,O,O,O,O,B-diag,I-diag,I-diag,I-diag,B-diag,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Bacterial vaginosis is caused by bacteria that...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,I-diag,B-diag,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>One of the bacterial diseases with the highest...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,B-diag,O,O,O,O,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Although the vast majority of bacteria are har...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Much like viral pathogens  infection by certai...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-med,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Some antidepressants are used as a treatment f...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,B-diag,B-diag,I-diag,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>However  existing data suggest that patients t...</td>\n",
       "      <td>O,O,O,O,O,O,O,B-med,O,O,O,O,B-med,I-med,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Latent TB is treated with either isoniazid or ...</td>\n",
       "      <td>O,O,O,O,O,O,B-med,O,B-med,O,O,O,O,O,O,O,O,B-me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>If a tuberculosis infection does become active...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-diag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>In        of active cases  the infection sprea...</td>\n",
       "      <td>O,O,O,O,O,I-diag,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Although viruses cause disruption of healthy h...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Examples of common human diseases caused by vi...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,I-diag,B-diag,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>All medical applications known so far involve ...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,B-med,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Buprenorphine has been shown experimentally   ...</td>\n",
       "      <td>B-med,O,O,O,O,O,O,O,O,O,B-diag,I-diag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Gabapentin  approved for treatment of seizures...</td>\n",
       "      <td>B-med,O,O,O,O,B-diag,O,B-diag,I-diag,O,O,O,O,O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Bupropion Wellbutrin  an anti depressant  is a...</td>\n",
       "      <td>B-med,B-med,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Carbamazepine is an approved treatment for bip...</td>\n",
       "      <td>B-med,O,O,O,O,O,B-diag,I-diag,O,B-diag,I-diag,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>The antiviral drugs amantadine and rimantadine...</td>\n",
       "      <td>O,O,O,B-med,O,B-med,O,O,O,O,O,B-med,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>The two classes of antiviral drugs used agains...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,B-diag,O,O,O,B-med,B-med,B-med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Influenza  commonly known as  the flu   is an ...</td>\n",
       "      <td>B-diag,O,O,O,O,I-diag,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               text  \\\n",
       "0            0  While bismuth compounds Pepto Bismol decreased...   \n",
       "1            1  Diarrhea  also spelled diarrhoea  is the condi...   \n",
       "2            2  Antiretroviral therapy ART is recommended for ...   \n",
       "3            3  The following drugs are considered as DMARDs  ...   \n",
       "4            4  The goals of treatment are to reduce pain  dec...   \n",
       "5            5  Bats are the most common source of rabies in h...   \n",
       "6            6  In       following the outbreak of severe acut...   \n",
       "7            7  Bacterial vaginosis is caused by bacteria that...   \n",
       "8            8  One of the bacterial diseases with the highest...   \n",
       "9            9  Although the vast majority of bacteria are har...   \n",
       "10          10  Much like viral pathogens  infection by certai...   \n",
       "11          11  Some antidepressants are used as a treatment f...   \n",
       "12          12  However  existing data suggest that patients t...   \n",
       "13          13  Latent TB is treated with either isoniazid or ...   \n",
       "14          14  If a tuberculosis infection does become active...   \n",
       "15          15  In        of active cases  the infection sprea...   \n",
       "16          16  Although viruses cause disruption of healthy h...   \n",
       "17          17  Examples of common human diseases caused by vi...   \n",
       "18          18  All medical applications known so far involve ...   \n",
       "19          19  Buprenorphine has been shown experimentally   ...   \n",
       "20          20  Gabapentin  approved for treatment of seizures...   \n",
       "21          21  Bupropion Wellbutrin  an anti depressant  is a...   \n",
       "22          22  Carbamazepine is an approved treatment for bip...   \n",
       "23          23  The antiviral drugs amantadine and rimantadine...   \n",
       "24          24  The two classes of antiviral drugs used agains...   \n",
       "25          25  Influenza  commonly known as  the flu   is an ...   \n",
       "\n",
       "                                                 tags  \n",
       "0   O,B-med,I-med,B-med,I-med,O,O,O,O,O,O,O,O,O,O,...  \n",
       "1   B-diag,O,O,B-diag,O,O,O,I-diag,O,O,O,O,O,O,O,B...  \n",
       "2   B-med,I-med,B-med,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "3   O,O,O,O,O,O,B-med,B-med,B-med,B-med,B-med,B-me...  \n",
       "4   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "5   O,O,O,O,O,O,O,B-diag,O,O,O,O,O,O,O,O,O,O,O,O,O...  \n",
       "6   O,O,O,O,O,B-diag,I-diag,I-diag,I-diag,B-diag,O...  \n",
       "7   O,O,O,O,O,O,O,O,I-diag,B-diag,O,O,O,O,O,O,O,O,...  \n",
       "8   O,O,O,O,O,O,O,O,O,O,O,B-diag,O,O,O,O,O,O,O,O,O...  \n",
       "9   O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "10  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-med,...  \n",
       "11  O,O,O,O,O,O,O,O,B-diag,B-diag,I-diag,O,O,O,O,O...  \n",
       "12  O,O,O,O,O,O,O,B-med,O,O,O,O,B-med,I-med,O,O,O,...  \n",
       "13  O,O,O,O,O,O,B-med,O,B-med,O,O,O,O,O,O,O,O,B-me...  \n",
       "14  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-diag...  \n",
       "15  O,O,O,O,O,I-diag,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B...  \n",
       "16  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "17  O,O,O,O,O,O,O,O,O,O,O,O,I-diag,B-diag,O,O,O,O,...  \n",
       "18  O,O,O,O,O,O,O,O,O,B-med,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "19              B-med,O,O,O,O,O,O,O,O,O,B-diag,I-diag  \n",
       "20  B-med,O,O,O,O,B-diag,O,B-diag,I-diag,O,O,O,O,O...  \n",
       "21  B-med,B-med,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "22  B-med,O,O,O,O,O,B-diag,I-diag,O,B-diag,I-diag,...  \n",
       "23  O,O,O,B-med,O,B-med,O,O,O,O,O,B-med,O,O,O,O,O,...  \n",
       "24  O,O,O,O,O,O,O,O,B-diag,O,O,O,B-med,B-med,B-med...  \n",
       "25  B-diag,O,O,O,O,I-diag,O,O,O,O,O,O,O,O,O,O,O,O,...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-med': 0, 'B-diag': 1, 'B-med': 2, 'I-diag': 3, 'O': 4}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = set()\n",
    "for tag in data.tags:\n",
    "    for t in tag.split(','):\n",
    "        tags.add(t)\n",
    "\n",
    "label2id = {k: v for v, k in enumerate(tags)}\n",
    "id2label = {v: k for v, k in enumerate(tags)}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-05\n",
    "MAX_GRAD_NORM = 10\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    tokenized_sentence = []\n",
    "    labels = []\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
    "\n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.text[index]  \n",
    "        word_labels = self.data.tags[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (26, 3)\n",
      "TRAIN Dataset: (21, 3)\n",
      "TEST Dataset: (5, 3)\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = data.sample(frac=train_size,random_state=200)\n",
    "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([  101,  1996,  2048,  4280,  1997,  3424, 24093,  2140,  5850,  2109,\n",
       "          2114, 24442,  2024, 11265, 27618,  5498,  8883,  2063, 25456,  9808,\n",
       "         20042, 10631, 21663, 23564, 28987, 21663, 17595,  3981,  4328, 21663,\n",
       "          1998,  2566, 10631, 21663,  1998,  1049,  5250, 25456, 29502,  7231,\n",
       "         16942,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'targets': tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  1996,  2048,  4280,  1997,  3424, 24093,  2140,  5850,  2109,\n",
       "         2114, 24442,  2024, 11265, 27618,  5498,  8883,  2063, 25456,  9808,\n",
       "        20042, 10631, 21663, 23564, 28987, 21663, 17595,  3981,  4328, 21663,\n",
       "         1998,  2566, 10631, 21663,  1998,  1049,  5250, 25456, 29502,  7231,\n",
       "        16942,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[0][\"ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]       O\n",
      "the         O\n",
      "two         O\n",
      "classes     O\n",
      "of          O\n",
      "anti        O\n",
      "##vira      O\n",
      "##l         O\n",
      "drugs       O\n",
      "used        O\n",
      "against     O\n",
      "influenza   B-diag\n",
      "are         O\n",
      "ne          O\n",
      "##uram      O\n",
      "##ini       O\n",
      "##das       O\n",
      "##e         O\n",
      "inhibitors  O\n",
      "os          B-med\n",
      "##elt       B-med\n",
      "##ami       B-med\n",
      "##vir       B-med\n",
      "za          B-med\n",
      "##nami      B-med\n",
      "##vir       B-med\n",
      "lan         B-med\n",
      "##ina       B-med\n",
      "##mi        B-med\n",
      "##vir       B-med\n",
      "and         O\n",
      "per         B-med\n",
      "##ami       B-med\n",
      "##vir       B-med\n",
      "and         O\n",
      "m           O\n",
      "protein     O\n",
      "inhibitors  O\n",
      "adamant     O\n",
      "##ane       O\n",
      "derivatives  O\n",
      "[SEP]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n",
      "[PAD]       O\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"ids\"][:200]), training_set[0][\"targets\"][:200]):\n",
    "  print('{0:10}  {1}'.format(token, id2label[label.item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "device = 'mps'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6977, device='mps:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "history = {\"loss\":[], \"acc\":[]}\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    for idx, batch in enumerate(training_loader):\n",
    "        \n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(tr_accuracy)\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 1.7080225944519043\n",
      "Training loss epoch: 1.3741031885147095\n",
      "Training accuracy epoch: 0.48543414587095995\n",
      "Training epoch: 2\n",
      "Training loss per 100 training steps: 1.0299434661865234\n",
      "Training loss epoch: 0.8648118178049723\n",
      "Training accuracy epoch: 0.8111399567808585\n",
      "Training epoch: 3\n",
      "Training loss per 100 training steps: 0.6114397048950195\n",
      "Training loss epoch: 0.6318400849898657\n",
      "Training accuracy epoch: 0.8367048003570212\n",
      "Training epoch: 4\n",
      "Training loss per 100 training steps: 0.9243603944778442\n",
      "Training loss epoch: 0.5293005506197611\n",
      "Training accuracy epoch: 0.8414711521024548\n",
      "Training epoch: 5\n",
      "Training loss per 100 training steps: 0.5655060410499573\n",
      "Training loss epoch: 0.512587328751882\n",
      "Training accuracy epoch: 0.8338489549368169\n",
      "Training epoch: 6\n",
      "Training loss per 100 training steps: 0.5061646699905396\n",
      "Training loss epoch: 0.4493737469116847\n",
      "Training accuracy epoch: 0.838715072219791\n",
      "Training epoch: 7\n",
      "Training loss per 100 training steps: 0.432691752910614\n",
      "Training loss epoch: 0.4407398005326589\n",
      "Training accuracy epoch: 0.8286315316801689\n",
      "Training epoch: 8\n",
      "Training loss per 100 training steps: 0.32243484258651733\n",
      "Training loss epoch: 0.4058378090461095\n",
      "Training accuracy epoch: 0.815016363979239\n",
      "Training epoch: 9\n",
      "Training loss per 100 training steps: 0.3028300404548645\n",
      "Training loss epoch: 0.4075089246034622\n",
      "Training accuracy epoch: 0.7999827772956801\n",
      "Training epoch: 10\n",
      "Training loss per 100 training steps: 0.33344751596450806\n",
      "Training loss epoch: 0.34528516232967377\n",
      "Training accuracy epoch: 0.8672095694619956\n",
      "Training epoch: 11\n",
      "Training loss per 100 training steps: 0.30969810485839844\n",
      "Training loss epoch: 0.3493104924758275\n",
      "Training accuracy epoch: 0.8675620210141575\n",
      "Training epoch: 12\n",
      "Training loss per 100 training steps: 0.20050781965255737\n",
      "Training loss epoch: 0.3320106665293376\n",
      "Training accuracy epoch: 0.8764567842039087\n",
      "Training epoch: 13\n",
      "Training loss per 100 training steps: 0.32836490869522095\n",
      "Training loss epoch: 0.2698025008042653\n",
      "Training accuracy epoch: 0.8925825949592788\n",
      "Training epoch: 14\n",
      "Training loss per 100 training steps: 0.23150742053985596\n",
      "Training loss epoch: 0.26451612263917923\n",
      "Training accuracy epoch: 0.859865342786012\n",
      "Training epoch: 15\n",
      "Training loss per 100 training steps: 0.25865018367767334\n",
      "Training loss epoch: 0.26568352182706195\n",
      "Training accuracy epoch: 0.8924830417387156\n",
      "Training epoch: 16\n",
      "Training loss per 100 training steps: 0.24185505509376526\n",
      "Training loss epoch: 0.24845203757286072\n",
      "Training accuracy epoch: 0.8998959487608373\n",
      "Training epoch: 17\n",
      "Training loss per 100 training steps: 0.18925604224205017\n",
      "Training loss epoch: 0.21172836174567541\n",
      "Training accuracy epoch: 0.8873426954364095\n",
      "Training epoch: 18\n",
      "Training loss per 100 training steps: 0.13105082511901855\n",
      "Training loss epoch: 0.24192509055137634\n",
      "Training accuracy epoch: 0.9080752813231939\n",
      "Training epoch: 19\n",
      "Training loss per 100 training steps: 0.2657802104949951\n",
      "Training loss epoch: 0.187704307337602\n",
      "Training accuracy epoch: 0.9172684161050003\n",
      "Training epoch: 20\n",
      "Training loss per 100 training steps: 0.1282472312450409\n",
      "Training loss epoch: 0.20952611913283667\n",
      "Training accuracy epoch: 0.9190469760815975\n",
      "Training epoch: 21\n",
      "Training loss per 100 training steps: 0.1699041724205017\n",
      "Training loss epoch: 0.18122842411200205\n",
      "Training accuracy epoch: 0.925061915859888\n",
      "Training epoch: 22\n",
      "Training loss per 100 training steps: 0.17878197133541107\n",
      "Training loss epoch: 0.15387250607212385\n",
      "Training accuracy epoch: 0.9401361420204518\n",
      "Training epoch: 23\n",
      "Training loss per 100 training steps: 0.16893243789672852\n",
      "Training loss epoch: 0.1653576319416364\n",
      "Training accuracy epoch: 0.9253715394187316\n",
      "Training epoch: 24\n",
      "Training loss per 100 training steps: 0.13561497628688812\n",
      "Training loss epoch: 0.13677252332369486\n",
      "Training accuracy epoch: 0.9455456870293754\n",
      "Training epoch: 25\n",
      "Training loss per 100 training steps: 0.1336025893688202\n",
      "Training loss epoch: 0.15389395381013551\n",
      "Training accuracy epoch: 0.9481625312450034\n",
      "Training epoch: 26\n",
      "Training loss per 100 training steps: 0.12304531037807465\n",
      "Training loss epoch: 0.11564348607013623\n",
      "Training accuracy epoch: 0.9480425518187691\n",
      "Training epoch: 27\n",
      "Training loss per 100 training steps: 0.10033296048641205\n",
      "Training loss epoch: 0.1291948805252711\n",
      "Training accuracy epoch: 0.9496709204040413\n",
      "Training epoch: 28\n",
      "Training loss per 100 training steps: 0.15009033679962158\n",
      "Training loss epoch: 0.1065088367710511\n",
      "Training accuracy epoch: 0.9571685664533804\n",
      "Training epoch: 29\n",
      "Training loss per 100 training steps: 0.07698389887809753\n",
      "Training loss epoch: 0.1219206154346466\n",
      "Training accuracy epoch: 0.9532439144084801\n",
      "Training epoch: 30\n",
      "Training loss per 100 training steps: 0.12037182599306107\n",
      "Training loss epoch: 0.1097831850250562\n",
      "Training accuracy epoch: 0.9488635507834958\n",
      "Training epoch: 31\n",
      "Training loss per 100 training steps: 0.08869943022727966\n",
      "Training loss epoch: 0.1104371336599191\n",
      "Training accuracy epoch: 0.960553972159406\n",
      "Training epoch: 32\n",
      "Training loss per 100 training steps: 0.10342823714017868\n",
      "Training loss epoch: 0.07809016310299437\n",
      "Training accuracy epoch: 0.9705147811787711\n",
      "Training epoch: 33\n",
      "Training loss per 100 training steps: 0.07543300092220306\n",
      "Training loss epoch: 0.08767423530419667\n",
      "Training accuracy epoch: 0.9649509724276827\n",
      "Training epoch: 34\n",
      "Training loss per 100 training steps: 0.04482235759496689\n",
      "Training loss epoch: 0.09010637986163299\n",
      "Training accuracy epoch: 0.9662083957277207\n",
      "Training epoch: 35\n",
      "Training loss per 100 training steps: 0.13210244476795197\n",
      "Training loss epoch: 0.06700932048261166\n",
      "Training accuracy epoch: 0.9768073759168852\n",
      "Training epoch: 36\n",
      "Training loss per 100 training steps: 0.05268421024084091\n",
      "Training loss epoch: 0.08573664414385955\n",
      "Training accuracy epoch: 0.9666671188891169\n",
      "Training epoch: 37\n",
      "Training loss per 100 training steps: 0.07228407263755798\n",
      "Training loss epoch: 0.06727658212184906\n",
      "Training accuracy epoch: 0.9750669971874112\n",
      "Training epoch: 38\n",
      "Training loss per 100 training steps: 0.08921396732330322\n",
      "Training loss epoch: 0.07113833725452423\n",
      "Training accuracy epoch: 0.9724076767850197\n",
      "Training epoch: 39\n",
      "Training loss per 100 training steps: 0.07735328376293182\n",
      "Training loss epoch: 0.05708853000154098\n",
      "Training accuracy epoch: 0.9784103798763942\n",
      "Training epoch: 40\n",
      "Training loss per 100 training steps: 0.06751541048288345\n",
      "Training loss epoch: 0.05136923911049962\n",
      "Training accuracy epoch: 0.9797264140251465\n",
      "Training epoch: 41\n",
      "Training loss per 100 training steps: 0.07048220932483673\n",
      "Training loss epoch: 0.060455511013666786\n",
      "Training accuracy epoch: 0.9804732463473812\n",
      "Training epoch: 42\n",
      "Training loss per 100 training steps: 0.05796496942639351\n",
      "Training loss epoch: 0.050042103976011276\n",
      "Training accuracy epoch: 0.9821144200938061\n",
      "Training epoch: 43\n",
      "Training loss per 100 training steps: 0.029541458934545517\n",
      "Training loss epoch: 0.06075748987495899\n",
      "Training accuracy epoch: 0.9782203540621276\n",
      "Training epoch: 44\n",
      "Training loss per 100 training steps: 0.06115439534187317\n",
      "Training loss epoch: 0.05308220194031795\n",
      "Training accuracy epoch: 0.9784607563324337\n",
      "Training epoch: 45\n",
      "Training loss per 100 training steps: 0.047700706869363785\n",
      "Training loss epoch: 0.04569392961760362\n",
      "Training accuracy epoch: 0.9860848151232021\n",
      "Training epoch: 46\n",
      "Training loss per 100 training steps: 0.03961918503046036\n",
      "Training loss epoch: 0.04373897798359394\n",
      "Training accuracy epoch: 0.9863214288501121\n",
      "Training epoch: 47\n",
      "Training loss per 100 training steps: 0.05472257360816002\n",
      "Training loss epoch: 0.04199157562106848\n",
      "Training accuracy epoch: 0.981826343909459\n",
      "Training epoch: 48\n",
      "Training loss per 100 training steps: 0.055993374437093735\n",
      "Training loss epoch: 0.03591957657287518\n",
      "Training accuracy epoch: 0.9829993369455181\n",
      "Training epoch: 49\n",
      "Training loss per 100 training steps: 0.040839117020368576\n",
      "Training loss epoch: 0.040902926586568356\n",
      "Training accuracy epoch: 0.9893939439785226\n",
      "Training epoch: 50\n",
      "Training loss per 100 training steps: 0.03328821808099747\n",
      "Training loss epoch: 0.03690131846815348\n",
      "Training accuracy epoch: 0.9893214373159366\n",
      "Training epoch: 51\n",
      "Training loss per 100 training steps: 0.026379402726888657\n",
      "Training loss epoch: 0.03158383180076877\n",
      "Training accuracy epoch: 0.9889698254953072\n",
      "Training epoch: 52\n",
      "Training loss per 100 training steps: 0.026955418288707733\n",
      "Training loss epoch: 0.027945431414991617\n",
      "Training accuracy epoch: 0.99112884383967\n",
      "Training epoch: 53\n",
      "Training loss per 100 training steps: 0.05933317542076111\n",
      "Training loss epoch: 0.029071692222108442\n",
      "Training accuracy epoch: 0.9923140585854644\n",
      "Training epoch: 54\n",
      "Training loss per 100 training steps: 0.01720568910241127\n",
      "Training loss epoch: 0.029760586097836494\n",
      "Training accuracy epoch: 0.9898208932192062\n",
      "Training epoch: 55\n",
      "Training loss per 100 training steps: 0.046177398413419724\n",
      "Training loss epoch: 0.02786856610327959\n",
      "Training accuracy epoch: 0.9905308858893896\n",
      "Training epoch: 56\n",
      "Training loss per 100 training steps: 0.04924008995294571\n",
      "Training loss epoch: 0.029197702649980783\n",
      "Training accuracy epoch: 0.9901435063135283\n",
      "Training epoch: 57\n",
      "Training loss per 100 training steps: 0.02704441547393799\n",
      "Training loss epoch: 0.02627228359536578\n",
      "Training accuracy epoch: 0.9921208567441188\n",
      "Training epoch: 58\n",
      "Training loss per 100 training steps: 0.016068199649453163\n",
      "Training loss epoch: 0.026152533789475758\n",
      "Training accuracy epoch: 0.9930028329960757\n",
      "Training epoch: 59\n",
      "Training loss per 100 training steps: 0.01884186640381813\n",
      "Training loss epoch: 0.026308964161823194\n",
      "Training accuracy epoch: 0.9947168826783969\n",
      "Training epoch: 60\n",
      "Training loss per 100 training steps: 0.015012066811323166\n",
      "Training loss epoch: 0.021621088807781536\n",
      "Training accuracy epoch: 0.9951906142284122\n",
      "Training epoch: 61\n",
      "Training loss per 100 training steps: 0.032960232347249985\n",
      "Training loss epoch: 0.023512642830610275\n",
      "Training accuracy epoch: 0.9931789532059169\n",
      "Training epoch: 62\n",
      "Training loss per 100 training steps: 0.025261877104640007\n",
      "Training loss epoch: 0.02275730607410272\n",
      "Training accuracy epoch: 0.994233686483634\n",
      "Training epoch: 63\n",
      "Training loss per 100 training steps: 0.036896608769893646\n",
      "Training loss epoch: 0.019586173196633656\n",
      "Training accuracy epoch: 0.9946770011082419\n",
      "Training epoch: 64\n",
      "Training loss per 100 training steps: 0.009755355305969715\n",
      "Training loss epoch: 0.01927879313006997\n",
      "Training accuracy epoch: 0.993052055979104\n",
      "Training epoch: 65\n",
      "Training loss per 100 training steps: 0.010174893774092197\n",
      "Training loss epoch: 0.020157845069964726\n",
      "Training accuracy epoch: 0.9933678563094531\n",
      "Training epoch: 66\n",
      "Training loss per 100 training steps: 0.03025795705616474\n",
      "Training loss epoch: 0.02084045686448614\n",
      "Training accuracy epoch: 0.9954692814625851\n",
      "Training epoch: 67\n",
      "Training loss per 100 training steps: 0.017654959112405777\n",
      "Training loss epoch: 0.019424808366845053\n",
      "Training accuracy epoch: 0.9936094877279128\n",
      "Training epoch: 68\n",
      "Training loss per 100 training steps: 0.0092805540189147\n",
      "Training loss epoch: 0.01760070150097211\n",
      "Training accuracy epoch: 0.9965453814160162\n",
      "Training epoch: 69\n",
      "Training loss per 100 training steps: 0.01052875816822052\n",
      "Training loss epoch: 0.014217129753281673\n",
      "Training accuracy epoch: 0.9957932197507251\n",
      "Training epoch: 70\n",
      "Training loss per 100 training steps: 0.017961561679840088\n",
      "Training loss epoch: 0.015231832163408399\n",
      "Training accuracy epoch: 0.9972626875072836\n",
      "Training epoch: 71\n",
      "Training loss per 100 training steps: 0.024398207664489746\n",
      "Training loss epoch: 0.013192881674816212\n",
      "Training accuracy epoch: 0.9966812300112496\n",
      "Training epoch: 72\n",
      "Training loss per 100 training steps: 0.01486684288829565\n",
      "Training loss epoch: 0.01651857482890288\n",
      "Training accuracy epoch: 0.9940974350373266\n",
      "Training epoch: 73\n",
      "Training loss per 100 training steps: 0.01249332632869482\n",
      "Training loss epoch: 0.015708369047691424\n",
      "Training accuracy epoch: 0.9961954218613297\n",
      "Training epoch: 74\n",
      "Training loss per 100 training steps: 0.01042911782860756\n",
      "Training loss epoch: 0.01166332233697176\n",
      "Training accuracy epoch: 0.9967401145361651\n",
      "Training epoch: 75\n",
      "Training loss per 100 training steps: 0.028518548235297203\n",
      "Training loss epoch: 0.015595135589440664\n",
      "Training accuracy epoch: 0.9938836887595487\n",
      "Training epoch: 76\n",
      "Training loss per 100 training steps: 0.011208586394786835\n",
      "Training loss epoch: 0.010843754280358553\n",
      "Training accuracy epoch: 0.998784597429298\n",
      "Training epoch: 77\n",
      "Training loss per 100 training steps: 0.011512759141623974\n",
      "Training loss epoch: 0.010825684837376079\n",
      "Training accuracy epoch: 0.9968339615655504\n",
      "Training epoch: 78\n",
      "Training loss per 100 training steps: 0.010873053222894669\n",
      "Training loss epoch: 0.009634741038704911\n",
      "Training accuracy epoch: 0.9973952514277772\n",
      "Training epoch: 79\n",
      "Training loss per 100 training steps: 0.009629860520362854\n",
      "Training loss epoch: 0.008291240548714995\n",
      "Training accuracy epoch: 0.9988155831973504\n",
      "Training epoch: 80\n",
      "Training loss per 100 training steps: 0.004699829965829849\n",
      "Training loss epoch: 0.009603850621109208\n",
      "Training accuracy epoch: 0.9972213453332364\n",
      "Training epoch: 81\n",
      "Training loss per 100 training steps: 0.00899399071931839\n",
      "Training loss epoch: 0.009402834810316563\n",
      "Training accuracy epoch: 0.9981324085316657\n",
      "Training epoch: 82\n",
      "Training loss per 100 training steps: 0.016548097133636475\n",
      "Training loss epoch: 0.010054860535698632\n",
      "Training accuracy epoch: 0.9976684582820106\n",
      "Training epoch: 83\n",
      "Training loss per 100 training steps: 0.012535068206489086\n",
      "Training loss epoch: 0.008978162271281084\n",
      "Training accuracy epoch: 0.9983409220962712\n",
      "Training epoch: 84\n",
      "Training loss per 100 training steps: 0.006306647323071957\n",
      "Training loss epoch: 0.006517534415858488\n",
      "Training accuracy epoch: 0.999496475327291\n",
      "Training epoch: 85\n",
      "Training loss per 100 training steps: 0.009921126998960972\n",
      "Training loss epoch: 0.007878889717782537\n",
      "Training accuracy epoch: 0.9979455980324347\n",
      "Training epoch: 86\n",
      "Training loss per 100 training steps: 0.009257355704903603\n",
      "Training loss epoch: 0.006306368935232361\n",
      "Training accuracy epoch: 0.9987885826634653\n",
      "Training epoch: 87\n",
      "Training loss per 100 training steps: 0.004069172777235508\n",
      "Training loss epoch: 0.006772260492046674\n",
      "Training accuracy epoch: 0.9992937853107344\n",
      "Training epoch: 88\n",
      "Training loss per 100 training steps: 0.005588850472122431\n",
      "Training loss epoch: 0.0073685588625570135\n",
      "Training accuracy epoch: 0.9978742889790705\n",
      "Training epoch: 89\n",
      "Training loss per 100 training steps: 0.008279915899038315\n",
      "Training loss epoch: 0.005502068204805255\n",
      "Training accuracy epoch: 0.9996159754224271\n",
      "Training epoch: 90\n",
      "Training loss per 100 training steps: 0.005441536195576191\n",
      "Training loss epoch: 0.00541421123004208\n",
      "Training accuracy epoch: 1.0\n",
      "Training epoch: 91\n",
      "Training loss per 100 training steps: 0.006723763421177864\n",
      "Training loss epoch: 0.005884078738745302\n",
      "Training accuracy epoch: 0.9988711586484346\n",
      "Training epoch: 92\n",
      "Training loss per 100 training steps: 0.005317219998687506\n",
      "Training loss epoch: 0.005157374505264063\n",
      "Training accuracy epoch: 1.0\n",
      "Training epoch: 93\n",
      "Training loss per 100 training steps: 0.00605869572609663\n",
      "Training loss epoch: 0.005846183785858254\n",
      "Training accuracy epoch: 0.999632892804699\n",
      "Training epoch: 94\n",
      "Training loss per 100 training steps: 0.00492693018168211\n",
      "Training loss epoch: 0.0050734344792241854\n",
      "Training accuracy epoch: 0.9996087636932707\n",
      "Training epoch: 95\n",
      "Training loss per 100 training steps: 0.00669129379093647\n",
      "Training loss epoch: 0.004784944428441425\n",
      "Training accuracy epoch: 0.9995780590717299\n",
      "Training epoch: 96\n",
      "Training loss per 100 training steps: 0.003377542132511735\n",
      "Training loss epoch: 0.003972668045510848\n",
      "Training accuracy epoch: 1.0\n",
      "Training epoch: 97\n",
      "Training loss per 100 training steps: 0.004854686092585325\n",
      "Training loss epoch: 0.005572193457434575\n",
      "Training accuracy epoch: 0.999652052887961\n",
      "Training epoch: 98\n",
      "Training loss per 100 training steps: 0.004409500863403082\n",
      "Training loss epoch: 0.004969953054872652\n",
      "Training accuracy epoch: 0.9996031746031746\n",
      "Training epoch: 99\n",
      "Training loss per 100 training steps: 0.0035702725872397423\n",
      "Training loss epoch: 0.0053607547500481205\n",
      "Training accuracy epoch: 0.999569336778639\n",
      "Training epoch: 100\n",
      "Training loss per 100 training steps: 0.004344870336353779\n",
      "Training loss epoch: 0.0038182447121168175\n",
      "Training accuracy epoch: 1.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    #print(eval_labels)\n",
    "    #print(eval_preds)\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    #print(labels)\n",
    "    #print(predictions)\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.29725661873817444\n",
      "Validation Loss: 0.3455126980940501\n",
      "Validation Accuracy: 0.9293154761904763\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        diag       0.50      0.57      0.53        23\n",
      "         med       0.94      0.69      0.79        45\n",
      "\n",
      "   micro avg       0.75      0.65      0.69        68\n",
      "   macro avg       0.72      0.63      0.66        68\n",
      "weighted avg       0.79      0.65      0.71        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add in the medication section , panadol for 3 times a day , augmentine for 1 time a day and xanax for 2 times a day and add in the diagnosis section the patient caught cold , fever and the flu .\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-med', 'B-med', 'B-med', 'O', 'O', 'O', 'O', 'O', 'O', 'B-med', 'B-med', 'B-med', 'O', 'O', 'O', 'O', 'O', 'O', 'B-med', 'B-med', 'B-med', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-diag', 'O', 'B-diag', 'O', 'O', 'B-diag', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Add in the medication section, Panadol for 3 times a day, Augmentine for 1 time a day and Xanax for 2 times a day and Add in the \\\n",
    "  diagnosis section the patient caught cold, fever and the flu.\"\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "# move to gpu\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "# forward pass\n",
    "outputs = model(ids, mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "word_level_predictions = []\n",
    "for pair in wp_preds:\n",
    "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "    # skip prediction\n",
    "    continue\n",
    "  else:\n",
    "    word_level_predictions.append(pair[1])\n",
    "\n",
    "# we join tokens, if they are not special ones\n",
    "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "print(str_rep)\n",
    "print(word_level_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'med',\n",
       "  'score': 0.993288,\n",
       "  'word': 'pan',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.99448085,\n",
       "  'word': '##ado',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.993292,\n",
       "  'word': '##l',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.9876632,\n",
       "  'word': 'aug',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.9885252,\n",
       "  'word': '##ment',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.993755,\n",
       "  'word': '##ine',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.94913113,\n",
       "  'word': 'x',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.90969384,\n",
       "  'word': '##ana',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.8871404,\n",
       "  'word': '##x',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'diag',\n",
       "  'score': 0.8485467,\n",
       "  'word': 'cold',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'diag',\n",
       "  'score': 0.9454517,\n",
       "  'word': 'fever',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'diag',\n",
       "  'score': 0.8680608,\n",
       "  'word': 'flu',\n",
       "  'start': None,\n",
       "  'end': None}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"token-classification\", model=model.to(\"cpu\"), tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "pipe(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForTokenClassification.from_pretrained('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'med',\n",
       "  'score': 0.993288,\n",
       "  'word': 'pan',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.99448085,\n",
       "  'word': '##ado',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.993292,\n",
       "  'word': '##l',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.9876632,\n",
       "  'word': 'aug',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.9885252,\n",
       "  'word': '##ment',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.993755,\n",
       "  'word': '##ine',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.94913113,\n",
       "  'word': 'x',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.90969384,\n",
       "  'word': '##ana',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'med',\n",
       "  'score': 0.8871404,\n",
       "  'word': '##x',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'diag',\n",
       "  'score': 0.8485467,\n",
       "  'word': 'cold',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'diag',\n",
       "  'score': 0.9454517,\n",
       "  'word': 'fever',\n",
       "  'start': None,\n",
       "  'end': None},\n",
       " {'entity_group': 'diag',\n",
       "  'score': 0.8680608,\n",
       "  'word': 'flu',\n",
       "  'start': None,\n",
       "  'end': None}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(task=\"token-classification\", model=model.to(\"cpu\"), tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "pipe(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3741031885147095,\n",
       "  0.8648118178049723,\n",
       "  0.6318400849898657,\n",
       "  0.5293005506197611,\n",
       "  0.512587328751882,\n",
       "  0.4493737469116847,\n",
       "  0.4407398005326589,\n",
       "  0.4058378090461095,\n",
       "  0.4075089246034622,\n",
       "  0.34528516232967377,\n",
       "  0.3493104924758275,\n",
       "  0.3320106665293376,\n",
       "  0.2698025008042653,\n",
       "  0.26451612263917923,\n",
       "  0.26568352182706195,\n",
       "  0.24845203757286072,\n",
       "  0.21172836174567541,\n",
       "  0.24192509055137634,\n",
       "  0.187704307337602,\n",
       "  0.20952611913283667,\n",
       "  0.18122842411200205,\n",
       "  0.15387250607212385,\n",
       "  0.1653576319416364,\n",
       "  0.13677252332369486,\n",
       "  0.15389395381013551,\n",
       "  0.11564348607013623,\n",
       "  0.1291948805252711,\n",
       "  0.1065088367710511,\n",
       "  0.1219206154346466,\n",
       "  0.1097831850250562,\n",
       "  0.1104371336599191,\n",
       "  0.07809016310299437,\n",
       "  0.08767423530419667,\n",
       "  0.09010637986163299,\n",
       "  0.06700932048261166,\n",
       "  0.08573664414385955,\n",
       "  0.06727658212184906,\n",
       "  0.07113833725452423,\n",
       "  0.05708853000154098,\n",
       "  0.05136923911049962,\n",
       "  0.060455511013666786,\n",
       "  0.050042103976011276,\n",
       "  0.06075748987495899,\n",
       "  0.05308220194031795,\n",
       "  0.04569392961760362,\n",
       "  0.04373897798359394,\n",
       "  0.04199157562106848,\n",
       "  0.03591957657287518,\n",
       "  0.040902926586568356,\n",
       "  0.03690131846815348,\n",
       "  0.03158383180076877,\n",
       "  0.027945431414991617,\n",
       "  0.029071692222108442,\n",
       "  0.029760586097836494,\n",
       "  0.02786856610327959,\n",
       "  0.029197702649980783,\n",
       "  0.02627228359536578,\n",
       "  0.026152533789475758,\n",
       "  0.026308964161823194,\n",
       "  0.021621088807781536,\n",
       "  0.023512642830610275,\n",
       "  0.02275730607410272,\n",
       "  0.019586173196633656,\n",
       "  0.01927879313006997,\n",
       "  0.020157845069964726,\n",
       "  0.02084045686448614,\n",
       "  0.019424808366845053,\n",
       "  0.01760070150097211,\n",
       "  0.014217129753281673,\n",
       "  0.015231832163408399,\n",
       "  0.013192881674816212,\n",
       "  0.01651857482890288,\n",
       "  0.015708369047691424,\n",
       "  0.01166332233697176,\n",
       "  0.015595135589440664,\n",
       "  0.010843754280358553,\n",
       "  0.010825684837376079,\n",
       "  0.009634741038704911,\n",
       "  0.008291240548714995,\n",
       "  0.009603850621109208,\n",
       "  0.009402834810316563,\n",
       "  0.010054860535698632,\n",
       "  0.008978162271281084,\n",
       "  0.006517534415858488,\n",
       "  0.007878889717782537,\n",
       "  0.006306368935232361,\n",
       "  0.006772260492046674,\n",
       "  0.0073685588625570135,\n",
       "  0.005502068204805255,\n",
       "  0.00541421123004208,\n",
       "  0.005884078738745302,\n",
       "  0.005157374505264063,\n",
       "  0.005846183785858254,\n",
       "  0.0050734344792241854,\n",
       "  0.004784944428441425,\n",
       "  0.003972668045510848,\n",
       "  0.005572193457434575,\n",
       "  0.004969953054872652,\n",
       "  0.0053607547500481205,\n",
       "  0.0038182447121168175],\n",
       " 'acc': [0.48543414587095995,\n",
       "  0.8111399567808585,\n",
       "  0.8367048003570212,\n",
       "  0.8414711521024548,\n",
       "  0.8338489549368169,\n",
       "  0.838715072219791,\n",
       "  0.8286315316801689,\n",
       "  0.815016363979239,\n",
       "  0.7999827772956801,\n",
       "  0.8672095694619956,\n",
       "  0.8675620210141575,\n",
       "  0.8764567842039087,\n",
       "  0.8925825949592788,\n",
       "  0.859865342786012,\n",
       "  0.8924830417387156,\n",
       "  0.8998959487608373,\n",
       "  0.8873426954364095,\n",
       "  0.9080752813231939,\n",
       "  0.9172684161050003,\n",
       "  0.9190469760815975,\n",
       "  0.925061915859888,\n",
       "  0.9401361420204518,\n",
       "  0.9253715394187316,\n",
       "  0.9455456870293754,\n",
       "  0.9481625312450034,\n",
       "  0.9480425518187691,\n",
       "  0.9496709204040413,\n",
       "  0.9571685664533804,\n",
       "  0.9532439144084801,\n",
       "  0.9488635507834958,\n",
       "  0.960553972159406,\n",
       "  0.9705147811787711,\n",
       "  0.9649509724276827,\n",
       "  0.9662083957277207,\n",
       "  0.9768073759168852,\n",
       "  0.9666671188891169,\n",
       "  0.9750669971874112,\n",
       "  0.9724076767850197,\n",
       "  0.9784103798763942,\n",
       "  0.9797264140251465,\n",
       "  0.9804732463473812,\n",
       "  0.9821144200938061,\n",
       "  0.9782203540621276,\n",
       "  0.9784607563324337,\n",
       "  0.9860848151232021,\n",
       "  0.9863214288501121,\n",
       "  0.981826343909459,\n",
       "  0.9829993369455181,\n",
       "  0.9893939439785226,\n",
       "  0.9893214373159366,\n",
       "  0.9889698254953072,\n",
       "  0.99112884383967,\n",
       "  0.9923140585854644,\n",
       "  0.9898208932192062,\n",
       "  0.9905308858893896,\n",
       "  0.9901435063135283,\n",
       "  0.9921208567441188,\n",
       "  0.9930028329960757,\n",
       "  0.9947168826783969,\n",
       "  0.9951906142284122,\n",
       "  0.9931789532059169,\n",
       "  0.994233686483634,\n",
       "  0.9946770011082419,\n",
       "  0.993052055979104,\n",
       "  0.9933678563094531,\n",
       "  0.9954692814625851,\n",
       "  0.9936094877279128,\n",
       "  0.9965453814160162,\n",
       "  0.9957932197507251,\n",
       "  0.9972626875072836,\n",
       "  0.9966812300112496,\n",
       "  0.9940974350373266,\n",
       "  0.9961954218613297,\n",
       "  0.9967401145361651,\n",
       "  0.9938836887595487,\n",
       "  0.998784597429298,\n",
       "  0.9968339615655504,\n",
       "  0.9973952514277772,\n",
       "  0.9988155831973504,\n",
       "  0.9972213453332364,\n",
       "  0.9981324085316657,\n",
       "  0.9976684582820106,\n",
       "  0.9983409220962712,\n",
       "  0.999496475327291,\n",
       "  0.9979455980324347,\n",
       "  0.9987885826634653,\n",
       "  0.9992937853107344,\n",
       "  0.9978742889790705,\n",
       "  0.9996159754224271,\n",
       "  1.0,\n",
       "  0.9988711586484346,\n",
       "  1.0,\n",
       "  0.999632892804699,\n",
       "  0.9996087636932707,\n",
       "  0.9995780590717299,\n",
       "  1.0,\n",
       "  0.999652052887961,\n",
       "  0.9996031746031746,\n",
       "  0.999569336778639,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 10000x5000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(EPOCHS)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(100,50))\n",
    "\n",
    "\n",
    "plt.subplot(10,10,1)\n",
    "plt.plot(x,history['loss'])\n",
    "plt.title('LOSS')\n",
    "\n",
    "\n",
    "plt.subplot(10,10,2)\n",
    "plt.plot(x,history['acc'])\n",
    "plt.title('ACCURACY')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3ff891de104f34902320d5a471fba75660d2839994b15e30fd656f3c3698ebf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
